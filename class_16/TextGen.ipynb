{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import re\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py:2717: DtypeWarning: Columns (15,30,31,32,36,37,38,42,43,44,45,46,47,50,51,52,56,57,58,59,60,61,62,63,64,65,66,67) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    Read a great interview with Donald Trump that ...\n",
       "1    Congratulations to Evan Lysacek for being nomi...\n",
       "2    I was on The View this morning. We talked abou...\n",
       "3    Tomorrow night's episode of The Apprentice del...\n",
       "4    Donald Trump Partners with TV1 on New Reality ...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = pd.read_csv('./data/trump_tw.csv')\n",
    "ds.text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read a great interview with Donald Trump that appeared in The New York Times Magazine: http://tinyurl.com/qsx4o6 Congratulations to Evan Lysacek for being nominated SI sportsman of the year. He's a great guy, and he has my vote!  #EvanForSI I was on The View this morning. We talked about The Apprentice. Tonight's episode is a great one--tough, exciting and surprising. 10 pm/NBC Tomorrow night's episode of The Apprentice delivers excitement at QVC along with appearances by Isaac Mizrahi and Cathie Black. 10 pm on NBC Donald Trump Partners with TV1 on New Reality Series Entitled, Omarosa's Ultimate Merger: http://tinyurl.com/yk5m3lc I'll be appearing on Larry King Live for his final show, Thursday night at 9 p.m., CNN. Larry's been on TV for 25 years... I'll be on The Late Show with David Letterman tonight--be sure to tune in for a great show. 11:30 pm on CBS. Watch the Miss Universe competition LIVE from the Bahamas - Sunday, 8/23 @ 9pm (ET) on NBC: http://tinyurl.com/mrzad9 Watch video\n"
     ]
    }
   ],
   "source": [
    "# Take all the text together\n",
    "\n",
    "data = ' '.join([ix for ix in ds.text])\n",
    "print data[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set(['\\x83', '\\x87', '\\x8b', '\\x8f', '\\x93', '\\x97', '\\x9b', '\\x9f', ' ', '\\xa3', '$', '\\xa7', '(', '\\xab', ',', '\\xaf', '0', '\\xb3', '4', '\\xb7', '8', '\\xbb', '\\xbf', '@', '\\xc3', 'D', 'H', 'L', 'P', 'T', '\\xd7', 'X', '\\\\', '`', '\\xe3', 'd', '\\xe7', 'h', 'l', '\\xef', 'p', 't', 'x', '|', '\\x80', '\\x84', '\\x88', '\\x8c', '\\x90', '\\x94', '\\x98', '\\x9c', '\\xa0', '#', '\\xa4', \"'\", '\\xa8', '+', '\\xac', '/', '\\xb0', '3', '\\xb4', '7', '\\xb8', ';', '\\xbc', '?', 'C', '\\xc4', 'G', 'K', 'O', 'S', 'W', '[', '_', 'c', '\\xe4', 'g', '\\xe8', 'k', 'o', '\\xf0', 's', '\\xf4', 'w', '{', '\\x81', '\\x85', '\\x89', '\\n', '\\x8d', '\\x91', '\\x95', '\\x99', '\\x9d', '\\xa1', '\"', '\\xa5', '&', '\\xa9', '*', '\\xad', '.', '\\xb1', '2', '\\xb5', '6', '\\xb9', ':', '\\xbd', 'B', '\\xc5', 'F', 'J', 'N', 'R', 'V', 'Z', '\\xe1', 'b', '\\xe5', 'f', '\\xe9', 'j', 'n', 'r', 'v', 'z', '~', '\\x82', '\\x86', '\\x8a', '\\r', '\\x8e', '\\x92', '\\x96', '\\x9a', '\\x9e', '!', '\\xa2', '%', '\\xa6', ')', '\\xaa', '-', '\\xae', '1', '\\xb2', '5', '9', '\\xba', '=', '\\xbe', 'A', '\\xc2', 'E', 'I', 'M', 'Q', 'U', 'Y', ']', 'a', '\\xe2', 'e', '\\xe6', 'i', 'm', 'q', 'u', 'y', '}'])\n",
      "174\n"
     ]
    }
   ],
   "source": [
    "print set(data)\n",
    "print len(set(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create Vocab\n",
    "vocab = list(set(data))\n",
    "\n",
    "i2c, c2i = {}, {}\n",
    "\n",
    "for idx, chx in enumerate(vocab):\n",
    "    i2c[idx] = chx\n",
    "    c2i[chx] = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 17, 174)\n"
     ]
    }
   ],
   "source": [
    "def get_onehot(x):\n",
    "    # Take input a string and convert to one-hot encoding\n",
    "    vec_size = len(c2i.keys())\n",
    "    n_seq = len(x)\n",
    "    data = np.zeros((1, n_seq, vec_size))\n",
    "    \n",
    "    # For each element in the list\n",
    "    for ix in range(n_seq):\n",
    "        curr_char = x[ix]\n",
    "        oh_index = c2i[curr_char]\n",
    "        data[:, ix, oh_index] = 1\n",
    "    return data\n",
    "\n",
    "print get_onehot('this is my string').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 112, 174)\n",
      "(1, 127, 174)\n",
      "(1, 139, 174)\n",
      "(1, 140, 174)\n",
      "(1, 116, 174)\n",
      "(1, 122, 174)\n",
      "(1, 108, 174)\n",
      "(1, 117, 174)\n",
      "(1, 115, 174)\n",
      "(1, 102, 174)\n"
     ]
    }
   ],
   "source": [
    "for ix in ds.text[:10]:\n",
    "    print get_onehot(ix).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CharNN(nn.Module):\n",
    "    def __init__(self, in_shape=None, out_shape=None, hidden_shape=None):\n",
    "        super(CharNN, self).__init__()\n",
    "        self.in_shape = in_shape\n",
    "        self.out_shape = out_shape\n",
    "        self.hidden_shape = hidden_shape\n",
    "        self.n_layers = 1\n",
    "        \n",
    "        self.rnn = nn.LSTM(\n",
    "            input_size=self.in_shape,\n",
    "            hidden_size=self.hidden_shape,\n",
    "            num_layers=self.n_layers,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.out = nn.Linear(self.hidden_shape, self.out_shape)\n",
    "    \n",
    "    def forward(self, x, h):\n",
    "        r_out, h_state = self.rnn(x, h)\n",
    "        \n",
    "        outs = []\n",
    "        for ix in range(r_out.size(1)):\n",
    "            current_out = F.softmax(self.out(r_out[:, ix, :]))\n",
    "            outs.append(current_out)\n",
    "        return torch.stack(outs, dim=1), h_state\n",
    "    \n",
    "    def predict(self, char, h=None, top_k=None):\n",
    "        if h is None:\n",
    "            h = self.init_hidden(1, gpu=False)\n",
    "        \n",
    "        x = get_onehot(char)\n",
    "        out, h = self.forward(torch.FloatTensor(x), h)\n",
    "        \n",
    "        p = out.data\n",
    "        if top_k is None:\n",
    "            top_ch = np.arange(self.out_shape)\n",
    "        else:\n",
    "            p, top_ch = p.topk(top_k)\n",
    "            top_ch = top_ch.numpy().squeeze()\n",
    "        \n",
    "        p = p.numpy().squeeze()\n",
    "        char = np.random.choice(top_ch, p=p/p.sum())\n",
    "        return i2c[char], h\n",
    "    \n",
    "    def init_hidden(self, batch_size, gpu=True):\n",
    "        if gpu:\n",
    "            return (Variable(torch.zeros(self.n_layers, batch_size, self.hidden_shape).cuda()),\n",
    "                    Variable(torch.zeros(self.n_layers, batch_size, self.hidden_shape)).cuda())\n",
    "        return (Variable(torch.zeros(self.n_layers, batch_size, self.hidden_shape)),\n",
    "                Variable(torch.zeros(self.n_layers, batch_size, self.hidden_shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CharNN(\n",
       "  (rnn): LSTM(174, 128, batch_first=True)\n",
       "  (out): Linear(in_features=128, out_features=174, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CharNN(in_shape=174, out_shape=174, hidden_shape=256)\n",
    "model.cuda()\n",
    "# print model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# model.predict('a', top_k=20)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 5.15909719467 at Epoch: 0 | Seq: 0\n",
      "Loss: 4.97706508636 at Epoch: 0 | Seq: 1000\n",
      "Loss: 4.99024248123 at Epoch: 0 | Seq: 2000\n",
      "Loss: 5.02281427383 at Epoch: 0 | Seq: 3000\n",
      "Loss: 4.96628522873 at Epoch: 0 | Seq: 4000\n",
      "Overall Average Loss: 5.01461648941 at Epoch: 0\n",
      "Loss: 5.00101280212 at Epoch: 1 | Seq: 0\n",
      "Loss: 4.91032266617 at Epoch: 1 | Seq: 1000\n",
      "Loss: 4.90067529678 at Epoch: 1 | Seq: 2000\n",
      "Loss: 4.94082164764 at Epoch: 1 | Seq: 3000\n",
      "Loss: 4.94284772873 at Epoch: 1 | Seq: 4000\n",
      "Overall Average Loss: 4.9568529129 at Epoch: 1\n",
      "Loss: 4.94118452072 at Epoch: 2 | Seq: 0\n",
      "Loss: 4.93541955948 at Epoch: 2 | Seq: 1000\n",
      "Loss: 4.89382219315 at Epoch: 2 | Seq: 2000\n",
      "Loss: 4.93845129013 at Epoch: 2 | Seq: 3000\n",
      "Loss: 4.93059587479 at Epoch: 2 | Seq: 4000\n",
      "Overall Average Loss: 4.94334697723 at Epoch: 2\n",
      "Loss: 4.90147352219 at Epoch: 3 | Seq: 0\n",
      "Loss: 4.89795398712 at Epoch: 3 | Seq: 1000\n",
      "Loss: 4.84971761703 at Epoch: 3 | Seq: 2000\n",
      "Loss: 4.89255046844 at Epoch: 3 | Seq: 3000\n",
      "Loss: 4.8633184433 at Epoch: 3 | Seq: 4000\n",
      "Overall Average Loss: 4.90615224838 at Epoch: 3\n",
      "Loss: 4.8406162262 at Epoch: 4 | Seq: 0\n",
      "Loss: 4.93510961533 at Epoch: 4 | Seq: 1000\n",
      "Loss: 4.77672100067 at Epoch: 4 | Seq: 2000\n",
      "Loss: 4.82117366791 at Epoch: 4 | Seq: 3000\n",
      "Loss: 4.82535934448 at Epoch: 4 | Seq: 4000\n",
      "Overall Average Loss: 4.86381578445 at Epoch: 4\n",
      "Loss: 4.80936002731 at Epoch: 5 | Seq: 0\n",
      "Loss: 4.81814575195 at Epoch: 5 | Seq: 1000\n",
      "Loss: 4.76243829727 at Epoch: 5 | Seq: 2000\n",
      "Loss: 4.81608390808 at Epoch: 5 | Seq: 3000\n",
      "Loss: 4.81065988541 at Epoch: 5 | Seq: 4000\n",
      "Overall Average Loss: 4.84548473358 at Epoch: 5\n",
      "Loss: 4.79058361053 at Epoch: 6 | Seq: 0\n",
      "Loss: 4.7874417305 at Epoch: 6 | Seq: 1000\n",
      "Loss: 4.74918270111 at Epoch: 6 | Seq: 2000\n",
      "Loss: 4.80644893646 at Epoch: 6 | Seq: 3000\n",
      "Loss: 4.79901361465 at Epoch: 6 | Seq: 4000\n",
      "Overall Average Loss: 4.82596731186 at Epoch: 6\n",
      "Loss: 4.78466796875 at Epoch: 7 | Seq: 0\n",
      "Loss: 4.78766965866 at Epoch: 7 | Seq: 1000\n",
      "Loss: 4.74573040009 at Epoch: 7 | Seq: 2000\n",
      "Loss: 4.8040060997 at Epoch: 7 | Seq: 3000\n",
      "Loss: 4.79865169525 at Epoch: 7 | Seq: 4000\n",
      "Overall Average Loss: 4.81483793259 at Epoch: 7\n",
      "Loss: 4.7441649437 at Epoch: 8 | Seq: 0\n",
      "Loss: 4.76948451996 at Epoch: 8 | Seq: 1000\n",
      "Loss: 4.75539588928 at Epoch: 8 | Seq: 2000\n",
      "Loss: 4.79391527176 at Epoch: 8 | Seq: 3000\n",
      "Loss: 4.77839517593 at Epoch: 8 | Seq: 4000\n",
      "Overall Average Loss: 4.80721712112 at Epoch: 8\n",
      "Loss: 4.72901344299 at Epoch: 9 | Seq: 0\n",
      "Loss: 4.71439027786 at Epoch: 9 | Seq: 1000\n",
      "Loss: 4.74319314957 at Epoch: 9 | Seq: 2000\n",
      "Loss: 4.79187250137 at Epoch: 9 | Seq: 3000\n",
      "Loss: 4.77588605881 at Epoch: 9 | Seq: 4000\n",
      "Overall Average Loss: 4.80099391937 at Epoch: 9\n",
      "Loss: 4.69499921799 at Epoch: 10 | Seq: 0\n",
      "Loss: 4.71425437927 at Epoch: 10 | Seq: 1000\n",
      "Loss: 4.74021530151 at Epoch: 10 | Seq: 2000\n",
      "Loss: 4.77927541733 at Epoch: 10 | Seq: 3000\n",
      "Loss: 4.78043889999 at Epoch: 10 | Seq: 4000\n",
      "Overall Average Loss: 4.79673576355 at Epoch: 10\n",
      "Loss: 4.68929862976 at Epoch: 11 | Seq: 0\n",
      "Loss: 4.69274520874 at Epoch: 11 | Seq: 1000\n",
      "Loss: 4.74058771133 at Epoch: 11 | Seq: 2000\n",
      "Loss: 4.77687454224 at Epoch: 11 | Seq: 3000\n",
      "Loss: 4.77691364288 at Epoch: 11 | Seq: 4000\n",
      "Overall Average Loss: 4.79235219955 at Epoch: 11\n",
      "Loss: 4.68445682526 at Epoch: 12 | Seq: 0\n",
      "Loss: 4.6728053093 at Epoch: 12 | Seq: 1000\n",
      "Loss: 4.73190832138 at Epoch: 12 | Seq: 2000\n",
      "Loss: 4.7770152092 at Epoch: 12 | Seq: 3000\n",
      "Loss: 4.77131891251 at Epoch: 12 | Seq: 4000\n",
      "Overall Average Loss: 4.78908348083 at Epoch: 12\n",
      "Loss: 4.68385887146 at Epoch: 13 | Seq: 0\n",
      "Loss: 4.679666996 at Epoch: 13 | Seq: 1000\n",
      "Loss: 4.7343454361 at Epoch: 13 | Seq: 2000\n",
      "Loss: 4.77705001831 at Epoch: 13 | Seq: 3000\n",
      "Loss: 4.7742061615 at Epoch: 13 | Seq: 4000\n",
      "Overall Average Loss: 4.78585577011 at Epoch: 13\n",
      "Loss: 4.68649053574 at Epoch: 14 | Seq: 0\n",
      "Loss: 4.68320417404 at Epoch: 14 | Seq: 1000\n",
      "Loss: 4.73708057404 at Epoch: 14 | Seq: 2000\n",
      "Loss: 4.77693891525 at Epoch: 14 | Seq: 3000\n",
      "Loss: 4.77261447906 at Epoch: 14 | Seq: 4000\n",
      "Overall Average Loss: 4.78336334229 at Epoch: 14\n",
      "Loss: 4.70069360733 at Epoch: 15 | Seq: 0\n",
      "Loss: 4.69114351273 at Epoch: 15 | Seq: 1000\n",
      "Loss: 4.72595357895 at Epoch: 15 | Seq: 2000\n",
      "Loss: 4.77831363678 at Epoch: 15 | Seq: 3000\n",
      "Loss: 4.76673984528 at Epoch: 15 | Seq: 4000\n",
      "Overall Average Loss: 4.78087329865 at Epoch: 15\n",
      "Loss: 4.68156814575 at Epoch: 16 | Seq: 0\n",
      "Loss: 4.68270492554 at Epoch: 16 | Seq: 1000\n",
      "Loss: 4.71058368683 at Epoch: 16 | Seq: 2000\n",
      "Loss: 4.76470279694 at Epoch: 16 | Seq: 3000\n",
      "Loss: 4.76274967194 at Epoch: 16 | Seq: 4000\n",
      "Overall Average Loss: 4.77561664581 at Epoch: 16\n",
      "Loss: 4.68290948868 at Epoch: 17 | Seq: 0\n",
      "Loss: 4.66877651215 at Epoch: 17 | Seq: 1000\n",
      "Loss: 4.71424484253 at Epoch: 17 | Seq: 2000\n",
      "Loss: 4.75549221039 at Epoch: 17 | Seq: 3000\n",
      "Loss: 4.76944351196 at Epoch: 17 | Seq: 4000\n",
      "Overall Average Loss: 4.77091121674 at Epoch: 17\n",
      "Loss: 4.67509889603 at Epoch: 18 | Seq: 0\n",
      "Loss: 4.64724445343 at Epoch: 18 | Seq: 1000\n",
      "Loss: 4.70277452469 at Epoch: 18 | Seq: 2000\n",
      "Loss: 4.74774503708 at Epoch: 18 | Seq: 3000\n",
      "Loss: 4.76122236252 at Epoch: 18 | Seq: 4000\n",
      "Overall Average Loss: 4.76628923416 at Epoch: 18\n",
      "Loss: 4.67165565491 at Epoch: 19 | Seq: 0\n",
      "Loss: 4.64776039124 at Epoch: 19 | Seq: 1000\n",
      "Loss: 4.69849014282 at Epoch: 19 | Seq: 2000\n",
      "Loss: 4.75153541565 at Epoch: 19 | Seq: 3000\n",
      "Loss: 4.76596164703 at Epoch: 19 | Seq: 4000\n",
      "Overall Average Loss: 4.76366376877 at Epoch: 19\n",
      "Loss: 4.67479324341 at Epoch: 20 | Seq: 0\n",
      "Loss: 4.65800619125 at Epoch: 20 | Seq: 1000\n",
      "Loss: 4.70019865036 at Epoch: 20 | Seq: 2000\n",
      "Loss: 4.74513339996 at Epoch: 20 | Seq: 3000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-60ae5b1ed0fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0;31m# print pred.squeeze().shape, y.shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-a91385717206>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, h)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mix\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0mcurrent_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr_out\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m             \u001b[0mouts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/nn/modules/linear.pyc\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/torch/nn/modules/module.pyc\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    516\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOrderedDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 518\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    519\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'_parameters'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m             \u001b[0m_parameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_parameters'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Set to train mode\n",
    "model.cuda()\n",
    "model.train()\n",
    "N = 5000\n",
    "\n",
    "for epoch in range(50):\n",
    "    total_loss = 0\n",
    "    # For each sequence\n",
    "    for qx in range(N):\n",
    "        seqx = ds.text[qx]\n",
    "        h_state = model.init_hidden(1)\n",
    "        input_seq = seqx[:-1]\n",
    "        target_seq = seqx[1:]\n",
    "        \n",
    "        x = Variable(torch.FloatTensor(get_onehot(input_seq)), requires_grad=True).cuda()\n",
    "        y = Variable(torch.LongTensor(get_onehot(target_seq).argmax(2))).cuda()\n",
    "        \n",
    "        model.zero_grad()\n",
    "        pred, h_state = model.forward(x, h_state)\n",
    "        # print pred.squeeze().shape, y.shape\n",
    "        loss = criterion(pred.squeeze(), y.squeeze())\n",
    "        \n",
    "        # optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        # gradient clipping to solve exploding/vanishing grads\n",
    "        # clip = 5.0\n",
    "        # nn.utils.clip_grad_norm(net.parameters(), clip)\n",
    "        \n",
    "        optimizer.step()\n",
    "        total_loss += loss\n",
    "        if qx%(N/5) == 0:\n",
    "            print 'Loss: {} at Epoch: {} | Seq: {}'.format(loss, epoch, qx)\n",
    "        \n",
    "    print \"Overall Average Loss: {} at Epoch: {}\".format(total_loss / float(N), epoch)\n",
    "    \n",
    "    # Save model checkpoints\n",
    "    if epoch % 10 == 0:\n",
    "        torch.save(model.state_dict(), \"./data/checkpoints/text_gen/model_256h_epoch_{}.ckpt\".format(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pe the the the the the the the he the the the there the the he the he the the the he the he the the the the the the the the the the the he the the the the the the the the the the the the the the the the the the he the the the he the the the the the the the the the the the the the the the the he the the the the the the the the the the the there the the the the the there the the the the the the the the the the the the the he the he the the the the the the the the the he the the the the the the the the the the the the the the the the the the the the he he the he the the the thanonononononone the the the he the thanononononone the the he the the the the he he the the the the the the the the the the the the the there the the thanonononononononononononone he he the the the the the the the the the the there the the the the the the the the thanononononononononone the the the the the the the the the the the the the the the thanonononononononone the the the the the the the the the the the he the \n"
     ]
    }
   ],
   "source": [
    "sentence = 'p'\n",
    "model.cpu()\n",
    "for ix in range(1000):\n",
    "    ctx = sentence[-1]\n",
    "    out = model.predict(ctx, top_k=10)[0]\n",
    "    \n",
    "    sentence += out\n",
    "print sentence"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
