{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.datasets import make_regression\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean_01 = np.array([1, 0.5])\n",
    "cov_01 = np.array([[1, 0.1], [0.1, 1.2]])\n",
    "\n",
    "mean_02 = np.array([4, 5])\n",
    "cov_02 = np.array([[1, 0.1], [0.1, 1.2]])\n",
    "\n",
    "# print mean_01\n",
    "# print cov_01\n",
    "\n",
    "dist_01 = np.random.multivariate_normal(mean_01, cov_01, 500)\n",
    "dist_02 = np.random.multivariate_normal(mean_02, cov_02, 500)\n",
    "print dist_01.shape, dist_02.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(0)\n",
    "plt.xlim(-5, 10)\n",
    "plt.ylim(-5, 10)\n",
    "\n",
    "plt.scatter(dist_01[:, 0], dist_01[:, 1])\n",
    "plt.scatter(dist_02[:, 0], dist_02[:, 1], color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r = dist_01.shape[0] + dist_02.shape[0]\n",
    "c = dist_01.shape[1] + 1\n",
    "data = np.zeros((r, c))\n",
    "print data.shape\n",
    "\n",
    "data[:dist_01.shape[0], :2] = dist_01\n",
    "data[dist_01.shape[0]:, :2] = dist_02\n",
    "data[dist_01.shape[0]:, -1] = 1.0\n",
    "\n",
    "print data.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.shuffle(data)\n",
    "print data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "split = int(0.8 * data.shape[0])\n",
    "\n",
    "X_train = data[:split, :-1]\n",
    "X_test = data[split:, :-1]\n",
    "\n",
    "y_train = data[:split, -1]\n",
    "y_test = data[split:, -1]\n",
    "\n",
    "print X_train.shape, X_test.shape\n",
    "print y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# hypothesis function\n",
    "def hypothesis(x, w, b):\n",
    "    '''\n",
    "    function accepts input vector x, weight vector w,\n",
    "    and bias (intercept) b.\n",
    "    '''\n",
    "    h = (x*w).sum() + b\n",
    "    return sigmoid(h)\n",
    "\n",
    "# sigmoid function\n",
    "def sigmoid(z):\n",
    "    return 1.0 / (1.0 + np.exp(-1.0 * z))\n",
    "\n",
    "# error compute\n",
    "def get_error(y_true, x, w, b):\n",
    "    err = 0.0\n",
    "    \n",
    "    # Get number of examples\n",
    "    m = x.shape[0]\n",
    "    for ix in range(m):\n",
    "        # for each example compute the binary cross-entropy\n",
    "        if y_true[ix] == 1:\n",
    "            err += -1.0*np.log2(hypothesis(x[ix], w, b))\n",
    "        else:\n",
    "            err += -1.0*np.log2(1.0 - hypothesis(x[ix], w, b))\n",
    "    # get mean error\n",
    "    err = err / m\n",
    "    return err\n",
    "\n",
    "# error gradient\n",
    "def get_grads(y_true, x, w, b):\n",
    "    grad_w = np.zeros(w.shape)\n",
    "    grad_b = 0.0\n",
    "    \n",
    "    # Get number of examples\n",
    "    m = x.shape[0]\n",
    "    \n",
    "    for ix in range(m):\n",
    "        # for each example compute the gradients\n",
    "        grad_w += (y_true[ix] - hypothesis(x[ix], w, b))*(x[ix])*-1\n",
    "        grad_b += (y_true[ix] - hypothesis(x[ix], w, b))*(-1)\n",
    "    \n",
    "    # Get mean grads\n",
    "    grad_w = grad_w / m\n",
    "    grad_b = grad_b / m\n",
    "    return [grad_w, grad_b]\n",
    "\n",
    "# update weights using grad. desc.\n",
    "def grad_descent(x, y_true, w, b, learning_rate=0.1):\n",
    "    error = get_error(y_true, x, w, b)\n",
    "    [grad_w, grad_b] = get_grads(y_true, x, w, b)\n",
    "    \n",
    "    w = w - learning_rate*grad_w\n",
    "    b = b - learning_rate*grad_b\n",
    "    \n",
    "    return error, w, b\n",
    "\n",
    "def predict(x, w, b):\n",
    "    prob = hypothesis(x, w, b)\n",
    "    \n",
    "    if prob < 0.5:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "def get_acc(x_tst, y_tst, w, B):\n",
    "    y_pred = []\n",
    "    for ix in range(y_tst.shape[0]):\n",
    "        y_pred.append(predict(x_tst[ix], w, B))\n",
    "    y_pred = np.asarray(y_pred)\n",
    "    return float((y_pred==y_tst).sum())/y_tst.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loss = []\n",
    "acc = []\n",
    "W = 2*np.random.random((X_train.shape[1],))\n",
    "b = 5*np.random.random()\n",
    "\n",
    "print W\n",
    "print b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for ix in range(100):\n",
    "    l, W, b = grad_descent(X_train, y_train, W, b, learning_rate=0.5)\n",
    "    acc.append(get_acc(X_test, y_test, W, b))\n",
    "    loss.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(0)\n",
    "plt.plot(loss)\n",
    "\n",
    "plt.figure(1)\n",
    "plt.plot(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
